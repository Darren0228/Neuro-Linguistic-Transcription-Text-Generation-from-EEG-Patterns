{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Import:\n",
    "\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from mne.preprocessing import ICA\n",
    "import pywt\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "mne.set_log_level('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining File Paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing EDF Files:\n",
    "\n",
    "file_participant_1 = 'Data/RawData/Participant_1.edf'\n",
    "file_participant_2 = 'Data/RawData/Participant_2.edf'\n",
    "file_participant_3 = 'Data/RawData/Participant_3.edf'\n",
    "file_participant_4 = 'Data/RawData/Participant_4.edf'\n",
    "file_participant_5 = 'Data/RawData/Participant_5.edf'\n",
    "file_participant_6 = 'Data/RawData/Participant_6.edf'\n",
    "file_participant_7 = 'Data/RawData/Participant_7.edf'\n",
    "file_participant_8 = 'Data/RawData/Participant_8.edf'\n",
    "file_participant_9 = 'Data/RawData/Participant_9.edf'\n",
    "file_participant_10 = 'Data/RawData/Participant_10.edf'\n",
    "file_participant_11 = 'Data/RawData/Participant_11.edf'\n",
    "file_participant_12 = 'Data/RawData/Participant_12.edf'\n",
    "file_participant_13 = 'Data/RawData/Participant_13.edf'\n",
    "\n",
    "edf_data_files = [\n",
    "    file_participant_1,\n",
    "    file_participant_2,\n",
    "    file_participant_3,\n",
    "    file_participant_4,\n",
    "    file_participant_5,\n",
    "    file_participant_6,\n",
    "    file_participant_7,\n",
    "    file_participant_8,\n",
    "    file_participant_9,\n",
    "    file_participant_10,\n",
    "    file_participant_11,\n",
    "    file_participant_12,\n",
    "    file_participant_13\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting Channels of Interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COI:\n",
    "\n",
    "channels_of_interest = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the COI:\n",
    "\n",
    "participant_1_COI_dataset = mne.io.read_raw_edf(file_participant_1, preload = True).pick_channels(channels_of_interest)\n",
    "participant_2_COI_dataset = mne.io.read_raw_edf(file_participant_2, preload = True).pick_channels(channels_of_interest)\n",
    "participant_3_COI_dataset = mne.io.read_raw_edf(file_participant_3, preload = True).pick_channels(channels_of_interest)\n",
    "participant_4_COI_dataset = mne.io.read_raw_edf(file_participant_4, preload = True).pick_channels(channels_of_interest)\n",
    "participant_5_COI_dataset = mne.io.read_raw_edf(file_participant_5, preload = True).pick_channels(channels_of_interest)\n",
    "participant_6_COI_dataset = mne.io.read_raw_edf(file_participant_6, preload = True).pick_channels(channels_of_interest)\n",
    "participant_7_COI_dataset = mne.io.read_raw_edf(file_participant_7, preload = True).pick_channels(channels_of_interest)\n",
    "participant_8_COI_dataset = mne.io.read_raw_edf(file_participant_8, preload = True).pick_channels(channels_of_interest)\n",
    "participant_9_COI_dataset = mne.io.read_raw_edf(file_participant_9, preload = True).pick_channels(channels_of_interest)\n",
    "participant_10_COI_dataset = mne.io.read_raw_edf(file_participant_10, preload = True).pick_channels(channels_of_interest)\n",
    "participant_11_COI_dataset = mne.io.read_raw_edf(file_participant_11, preload = True).pick_channels(channels_of_interest)\n",
    "participant_12_COI_dataset = mne.io.read_raw_edf(file_participant_12, preload = True).pick_channels(channels_of_interest)\n",
    "participant_13_COI_dataset = mne.io.read_raw_edf(file_participant_13, preload = True).pick_channels(channels_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RawEDF | Participant_1.edf, 14 x 117760 (920.0 s), ~12.6 MB, data loaded>\n",
      "<RawEDF | Participant_2.edf, 14 x 116480 (910.0 s), ~12.5 MB, data loaded>\n",
      "<RawEDF | Participant_3.edf, 14 x 116608 (911.0 s), ~12.5 MB, data loaded>\n",
      "<RawEDF | Participant_4.edf, 14 x 116352 (909.0 s), ~12.4 MB, data loaded>\n",
      "<RawEDF | Participant_5.edf, 14 x 116224 (908.0 s), ~12.4 MB, data loaded>\n",
      "<RawEDF | Participant_6.edf, 14 x 116864 (913.0 s), ~12.5 MB, data loaded>\n",
      "<RawEDF | Participant_7.edf, 14 x 117376 (917.0 s), ~12.6 MB, data loaded>\n",
      "<RawEDF | Participant_8.edf, 14 x 116480 (910.0 s), ~12.5 MB, data loaded>\n",
      "<RawEDF | Participant_9.edf, 14 x 115840 (905.0 s), ~12.4 MB, data loaded>\n",
      "<RawEDF | Participant_10.edf, 14 x 116352 (909.0 s), ~12.4 MB, data loaded>\n",
      "<RawEDF | Participant_11.edf, 14 x 115840 (905.0 s), ~12.4 MB, data loaded>\n",
      "<RawEDF | Participant_12.edf, 14 x 116864 (913.0 s), ~12.5 MB, data loaded>\n",
      "<RawEDF | Participant_13.edf, 14 x 115840 (905.0 s), ~12.4 MB, data loaded>\n"
     ]
    }
   ],
   "source": [
    "# Resulting Raw EDF Info:\n",
    "\n",
    "print(participant_1_COI_dataset)\n",
    "print(participant_2_COI_dataset)\n",
    "print(participant_3_COI_dataset)\n",
    "print(participant_4_COI_dataset)\n",
    "print(participant_5_COI_dataset)\n",
    "print(participant_6_COI_dataset)\n",
    "print(participant_7_COI_dataset)\n",
    "print(participant_8_COI_dataset)\n",
    "print(participant_9_COI_dataset)\n",
    "print(participant_10_COI_dataset)\n",
    "print(participant_11_COI_dataset)\n",
    "print(participant_12_COI_dataset)\n",
    "print(participant_13_COI_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Preprocess Raw Data:\n",
    "\n",
    "def preprocess_raw_data(raw):\n",
    "\n",
    "    # Handling NaNs: Replace NaNs with the mean of the respective channel\n",
    "    raw_data = raw.get_data()\n",
    "\n",
    "    for i in range(raw_data.shape[0]):\n",
    "        nan_indices = np.isnan(raw_data[i])\n",
    "\n",
    "        if np.any(nan_indices):\n",
    "            mean_value = np.nanmean(raw_data[i])\n",
    "            raw_data[i, nan_indices] = mean_value\n",
    "\n",
    "    raw._data = raw_data\n",
    "\n",
    "    # Filtering: Bandpass filter between 0.5-30 Hz\n",
    "    raw.filter(0.5, 30., fir_design='firwin')\n",
    "    \n",
    "    # Artifact Removal: ICA\n",
    "    ica = mne.preprocessing.ICA(n_components = 14, random_state = 97, max_iter = 800)\n",
    "    ica.fit(raw)\n",
    "    raw = ica.apply(raw)\n",
    "    \n",
    "    # Spatial Filtering: Common Average Reference (CAR)\n",
    "    raw.set_eeg_reference('average', projection = True)\n",
    "    \n",
    "    # Channel Interpolation: Interpolate bad channels\n",
    "    raw.interpolate_bads()\n",
    "\n",
    "    # Baseline Correction: Apply baseline correction using the mean of the segment\n",
    "    raw.apply_function(lambda x: x - np.mean(x), picks = 'eeg')\n",
    "    \n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Preprocessing Function:\n",
    "\n",
    "participant_1_preprocessed_dataset = preprocess_raw_data(participant_1_COI_dataset)\n",
    "participant_2_preprocessed_dataset = preprocess_raw_data(participant_2_COI_dataset)\n",
    "participant_3_preprocessed_dataset = preprocess_raw_data(participant_3_COI_dataset)\n",
    "participant_4_preprocessed_dataset = preprocess_raw_data(participant_4_COI_dataset)\n",
    "participant_5_preprocessed_dataset = preprocess_raw_data(participant_5_COI_dataset)\n",
    "participant_6_preprocessed_dataset = preprocess_raw_data(participant_6_COI_dataset)\n",
    "participant_7_preprocessed_dataset = preprocess_raw_data(participant_7_COI_dataset)\n",
    "participant_8_preprocessed_dataset = preprocess_raw_data(participant_8_COI_dataset)\n",
    "participant_9_preprocessed_dataset = preprocess_raw_data(participant_9_COI_dataset)\n",
    "participant_10_preprocessed_dataset = preprocess_raw_data(participant_10_COI_dataset)\n",
    "participant_11_preprocessed_dataset = preprocess_raw_data(participant_11_COI_dataset)\n",
    "participant_12_preprocessed_dataset = preprocess_raw_data(participant_12_COI_dataset)\n",
    "participant_13_preprocessed_dataset = preprocess_raw_data(participant_13_COI_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Segmentation of Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation occurs as following:\n",
    "\n",
    "# First 30 secs -> removed since these serve as the adjustment period\n",
    "# 60 secs -> \"I\"\n",
    "# 30 secs -> Break\n",
    "# 60 secs -> \"Yes\"\n",
    "# 30 secs -> Break\n",
    "# 60 secs -> \"No\"\n",
    "# 30 secs -> Break\n",
    "# 60 secs -> \"Want\"\n",
    "# 30 secs -> Break\n",
    "# 60 secs -> \"Help\"\n",
    "# 30 secs -> Break\n",
    "# 60 secs -> \"More\"\n",
    "# 30 secs -> Break\n",
    "# 60 secs -> \"That\"\n",
    "# 30 secs -> Break\n",
    "# 60 secs -> \"Stop\"\n",
    "# 30 secs -> Break\n",
    "# 60 secs -> \"Open\"\n",
    "# 30 secs -> Break\n",
    "# 60 secs -> \"Close\"\n",
    "# Remaining time remove as it is redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Extract Segments:\n",
    "\n",
    "def extract_segment(raw, start_sec, duration_sec, label, sfreq):\n",
    "\n",
    "    start_sample = int(start_sec * sfreq)\n",
    "    end_sample = start_sample + int(duration_sec * sfreq)\n",
    "    segment = raw[:, start_sample:end_sample][0]\n",
    "    \n",
    "    return segment, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation Details:\n",
    "\n",
    "segments = [\n",
    "    (30, 60, \"I\"),\n",
    "    (120, 60, \"Yes\"),\n",
    "    (210, 60, \"No\"),\n",
    "    (300, 60, \"Want\"),\n",
    "    (390, 60, \"Help\"),\n",
    "    (480, 60, \"More\"),\n",
    "    (570, 60, \"That\"),\n",
    "    (660, 60, \"Stop\"),\n",
    "    (750, 60, \"Open\"),\n",
    "    (840, 60, \"Close\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Segments for each Individual Participant Part 1:\n",
    "\n",
    "# Extract segments for Participant 1:\n",
    "sfreq_participant_1 = participant_1_preprocessed_dataset.info['sfreq']\n",
    "segments_participant_1 = []\n",
    "\n",
    "for start, duration, label in segments:\n",
    "    segment, label = extract_segment(participant_1_preprocessed_dataset, start, duration, label, sfreq_participant_1)\n",
    "    segments_participant_1.append((segment, label))\n",
    "\n",
    "# Extract segments for Participant 2:\n",
    "sfreq_participant_2 = participant_2_preprocessed_dataset.info['sfreq']\n",
    "segments_participant_2 = []\n",
    "\n",
    "for start, duration, label in segments:\n",
    "    segment, label = extract_segment(participant_2_preprocessed_dataset, start, duration, label, sfreq_participant_2)\n",
    "    segments_participant_2.append((segment, label))\n",
    "\n",
    "# Extract segments for Participant 3:\n",
    "sfreq_participant_3 = participant_3_preprocessed_dataset.info['sfreq']\n",
    "segments_participant_3 = []\n",
    "\n",
    "for start, duration, label in segments:\n",
    "    segment, label = extract_segment(participant_3_preprocessed_dataset, start, duration, label, sfreq_participant_3)\n",
    "    segments_participant_3.append((segment, label))\n",
    "\n",
    "# Extract segments for Participant 4:\n",
    "sfreq_participant_4 = participant_4_preprocessed_dataset.info['sfreq']\n",
    "segments_participant_4 = []\n",
    "\n",
    "for start, duration, label in segments:\n",
    "    segment, label = extract_segment(participant_4_preprocessed_dataset, start, duration, label, sfreq_participant_4)\n",
    "    segments_participant_4.append((segment, label))\n",
    "\n",
    "# Extract segments for Participant 5:\n",
    "sfreq_participant_5 = participant_5_preprocessed_dataset.info['sfreq']\n",
    "segments_participant_5 = []\n",
    "\n",
    "for start, duration, label in segments:\n",
    "    segment, label = extract_segment(participant_5_preprocessed_dataset, start, duration, label, sfreq_participant_5)\n",
    "    segments_participant_5.append((segment, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Segments for each Individual Participant Part 2:\n",
    "\n",
    "# Extract segments for Participant 6:\n",
    "sfreq_participant_6 = participant_6_preprocessed_dataset.info['sfreq']\n",
    "segments_participant_6 = []\n",
    "\n",
    "for start, duration, label in segments:\n",
    "    segment, label = extract_segment(participant_6_preprocessed_dataset, start, duration, label, sfreq_participant_6)\n",
    "    segments_participant_6.append((segment, label))\n",
    "\n",
    "# Extract segments for Participant 7:\n",
    "sfreq_participant_7 = participant_7_preprocessed_dataset.info['sfreq']\n",
    "segments_participant_7 = []\n",
    "\n",
    "for start, duration, label in segments:\n",
    "    segment, label = extract_segment(participant_7_preprocessed_dataset, start, duration, label, sfreq_participant_7)\n",
    "    segments_participant_7.append((segment, label))\n",
    "\n",
    "# Extract segments for Participant 8:\n",
    "sfreq_participant_8 = participant_8_preprocessed_dataset.info['sfreq']\n",
    "segments_participant_8 = []\n",
    "\n",
    "for start, duration, label in segments:\n",
    "    segment, label = extract_segment(participant_8_preprocessed_dataset, start, duration, label, sfreq_participant_8)\n",
    "    segments_participant_8.append((segment, label))\n",
    "\n",
    "# Extract segments for Participant 9:\n",
    "sfreq_participant_9 = participant_9_preprocessed_dataset.info['sfreq']\n",
    "segments_participant_9 = []\n",
    "\n",
    "for start, duration, label in segments:\n",
    "    segment, label = extract_segment(participant_9_preprocessed_dataset, start, duration, label, sfreq_participant_9)\n",
    "    segments_participant_9.append((segment, label))\n",
    "\n",
    "# Extract segments for Participant 10:\n",
    "sfreq_participant_10 = participant_10_preprocessed_dataset.info['sfreq']\n",
    "segments_participant_10 = []\n",
    "\n",
    "for start, duration, label in segments:\n",
    "    segment, label = extract_segment(participant_10_preprocessed_dataset, start, duration, label, sfreq_participant_10)\n",
    "    segments_participant_10.append((segment, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Segments for each Individual Participant Part 3:\n",
    "\n",
    "# Extract segments for Participant 11:\n",
    "sfreq_participant_11 = participant_11_preprocessed_dataset.info['sfreq']\n",
    "segments_participant_11 = []\n",
    "\n",
    "for start, duration, label in segments:\n",
    "    segment, label = extract_segment(participant_11_preprocessed_dataset, start, duration, label, sfreq_participant_11)\n",
    "    segments_participant_11.append((segment, label))\n",
    "\n",
    "# Extract segments for Participant 12:\n",
    "sfreq_participant_12 = participant_12_preprocessed_dataset.info['sfreq']\n",
    "segments_participant_12 = []\n",
    "\n",
    "for start, duration, label in segments:\n",
    "    segment, label = extract_segment(participant_12_preprocessed_dataset, start, duration, label, sfreq_participant_12)\n",
    "    segments_participant_12.append((segment, label))\n",
    "\n",
    "# Extract segments for Participant 13:\n",
    "sfreq_participant_13 = participant_13_preprocessed_dataset.info['sfreq']\n",
    "segments_participant_13 = []\n",
    "\n",
    "for start, duration, label in segments:\n",
    "    segment, label = extract_segment(participant_13_preprocessed_dataset, start, duration, label, sfreq_participant_13)\n",
    "    segments_participant_13.append((segment, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[ 2.13238279e-04,  2.05378182e-04,  1.97904898e-04, ...,\n",
       "          -8.24021941e-06, -1.83166731e-05, -2.90499871e-05],\n",
       "         [ 1.72501481e-04,  1.69083200e-04,  1.65870594e-04, ...,\n",
       "          -5.31618240e-07, -8.17158515e-06, -1.95097882e-05],\n",
       "         [ 2.02836421e-04,  1.92313730e-04,  1.88531476e-04, ...,\n",
       "           8.07180431e-06,  1.96599803e-06, -3.20881890e-06],\n",
       "         ...,\n",
       "         [ 3.01715790e-04,  2.85883755e-04,  2.72007228e-04, ...,\n",
       "           4.12278394e-05,  3.37222051e-05,  2.58178307e-05],\n",
       "         [ 2.60535811e-04,  2.50385791e-04,  2.45094255e-04, ...,\n",
       "           5.66471968e-05,  4.43954440e-05,  3.10132867e-05],\n",
       "         [ 2.50443676e-04,  2.37106637e-04,  2.27500428e-04, ...,\n",
       "           4.29710885e-05,  3.23122293e-05,  2.26700920e-05]]),\n",
       "  'I'),\n",
       " (array([[-1.29501473e-05, -1.64963172e-05, -1.24686881e-05, ...,\n",
       "          -1.39144399e-06,  2.76310702e-07, -2.60156098e-06],\n",
       "         [ 2.21400884e-05,  1.78141132e-05,  2.14257918e-05, ...,\n",
       "           1.48753583e-06,  5.23568309e-06,  5.28069810e-06],\n",
       "         [ 2.37036327e-05,  2.77758079e-05,  3.31297544e-05, ...,\n",
       "          -1.00915151e-05, -5.22907997e-06, -3.56039162e-06],\n",
       "         ...,\n",
       "         [ 3.42929776e-05,  3.35151402e-05,  4.06586502e-05, ...,\n",
       "          -1.05204759e-05, -1.01298805e-05, -6.54404663e-06],\n",
       "         [ 2.04992588e-05,  1.65180969e-05,  1.91570057e-05, ...,\n",
       "          -1.43850762e-05, -1.00480856e-05, -1.50365919e-06],\n",
       "         [ 2.61344120e-05,  2.53799641e-05,  3.07713039e-05, ...,\n",
       "          -5.41724294e-06, -5.85370210e-06, -7.28591684e-06]]),\n",
       "  'Yes'),\n",
       " (array([[ 8.53128636e-05,  7.66780270e-05,  7.22736843e-05, ...,\n",
       "          -5.41474281e-07, -4.06767104e-06, -2.59520735e-06],\n",
       "         [-7.67999370e-06, -6.14898701e-06, -7.80952103e-06, ...,\n",
       "           4.30232478e-06, -3.91204000e-06, -1.03852509e-05],\n",
       "         [ 2.25322350e-05,  1.86159049e-05,  1.43432040e-05, ...,\n",
       "          -3.54405466e-06, -9.59599071e-06, -8.32895428e-06],\n",
       "         ...,\n",
       "         [-3.64964154e-06, -7.59482385e-06, -4.96982813e-06, ...,\n",
       "          -7.20162036e-06, -3.51902253e-06,  7.00992445e-06],\n",
       "         [-2.20527998e-05, -2.49948146e-05, -2.50156493e-05, ...,\n",
       "           1.30831735e-05,  1.60747647e-05,  1.99368080e-05],\n",
       "         [ 8.01847833e-06,  5.49792054e-06,  5.37240351e-06, ...,\n",
       "           2.46755814e-06,  5.31103870e-06,  1.33407142e-05]]),\n",
       "  'No'),\n",
       " (array([[ 4.34964907e-05,  4.66145391e-05,  4.05979117e-05, ...,\n",
       "          -4.90380846e-05, -5.90302346e-05, -6.48041120e-05],\n",
       "         [ 1.77320695e-05,  2.15183933e-05,  1.65301182e-05, ...,\n",
       "          -2.97168262e-05, -3.16820138e-05, -3.63073416e-05],\n",
       "         [ 4.03114464e-05,  4.22874649e-05,  3.84916792e-05, ...,\n",
       "          -3.11422977e-05, -4.05761851e-05, -4.38163546e-05],\n",
       "         ...,\n",
       "         [ 4.47128080e-05,  4.93470411e-05,  4.63239557e-05, ...,\n",
       "           7.61168927e-05,  6.92738176e-05,  6.46269335e-05],\n",
       "         [ 2.70734830e-05,  3.68058340e-05,  3.43985330e-05, ...,\n",
       "           2.40340705e-05,  1.81771849e-05,  1.01587480e-05],\n",
       "         [ 6.17513019e-05,  6.79655083e-05,  6.04780026e-05, ...,\n",
       "           1.80563579e-05,  1.62931930e-05,  8.86087536e-06]]),\n",
       "  'Want'),\n",
       " (array([[-6.72201774e-06,  1.05301383e-06,  8.88231830e-06, ...,\n",
       "          -1.04573511e-05, -1.07011260e-05, -8.52022564e-06],\n",
       "         [ 5.37904311e-06,  1.11240887e-05,  2.02423270e-05, ...,\n",
       "          -6.85689332e-06, -9.72020085e-06, -9.01382574e-06],\n",
       "         [-2.91950962e-05, -2.30754113e-05, -1.57185324e-05, ...,\n",
       "          -5.97898062e-06, -4.89089410e-06, -1.46719080e-06],\n",
       "         ...,\n",
       "         [-8.47546962e-06,  3.54641470e-06,  1.39077021e-05, ...,\n",
       "          -2.15119142e-05, -2.56416490e-05, -2.63114934e-05],\n",
       "         [-3.05829251e-06,  6.72179965e-06,  1.59801114e-05, ...,\n",
       "          -1.67321885e-05, -2.09368022e-05, -2.58238937e-05],\n",
       "         [-1.32984748e-05, -3.77414162e-06,  4.88436347e-06, ...,\n",
       "          -1.27432685e-06, -3.02580383e-06, -5.63240136e-06]]),\n",
       "  'Help'),\n",
       " (array([[-1.45841973e-05, -4.82245542e-06,  4.67165918e-06, ...,\n",
       "           8.11000164e-06,  1.22662295e-05,  1.33103463e-05],\n",
       "         [-1.19430247e-05, -5.04200586e-06,  6.22206707e-06, ...,\n",
       "          -2.18108263e-05, -1.77306478e-05, -1.05014457e-05],\n",
       "         [-2.78860487e-06,  2.86067991e-06,  1.19182419e-05, ...,\n",
       "           1.06571344e-05,  1.46338385e-05,  1.36454264e-05],\n",
       "         ...,\n",
       "         [-6.76728167e-06,  2.94525223e-06,  1.09475212e-05, ...,\n",
       "           2.36469193e-05,  3.18149668e-05,  3.04816721e-05],\n",
       "         [-9.12830010e-06,  2.08298401e-06,  1.26734677e-05, ...,\n",
       "           4.66871079e-06,  1.13876124e-05,  1.29284068e-05],\n",
       "         [-8.06694472e-06,  1.72109747e-06,  8.14835284e-06, ...,\n",
       "           9.79216728e-06,  1.85077095e-05,  2.11663098e-05]]),\n",
       "  'More'),\n",
       " (array([[-1.82258548e-05, -2.52010909e-05, -2.40535877e-05, ...,\n",
       "           1.97720888e-05,  2.59224393e-05,  2.24817450e-05],\n",
       "         [-1.36975535e-05, -2.40305299e-05, -2.75475476e-05, ...,\n",
       "          -2.30185078e-06,  3.78070241e-08, -1.47511181e-06],\n",
       "         [-8.92485441e-06, -9.95553422e-06, -9.39488660e-06, ...,\n",
       "           2.13623499e-05,  2.25222759e-05,  1.54671671e-05],\n",
       "         ...,\n",
       "         [ 3.50001662e-08, -5.46956681e-06, -1.37662135e-05, ...,\n",
       "           3.04452575e-05,  3.22905990e-05,  2.57701623e-05],\n",
       "         [ 8.13616063e-06, -1.53707178e-06, -1.07799267e-05, ...,\n",
       "           2.36517567e-05,  2.71623042e-05,  2.61919637e-05],\n",
       "         [ 3.06622056e-06, -9.96303311e-06, -2.72950859e-05, ...,\n",
       "           2.88153752e-05,  3.80699988e-05,  3.44207437e-05]]),\n",
       "  'That'),\n",
       " (array([[-6.81468772e-06, -4.53118423e-06, -5.96248832e-06, ...,\n",
       "           2.34358191e-06,  6.54486900e-06,  1.93045629e-05],\n",
       "         [-6.26866359e-06, -6.85037710e-06, -6.08765793e-06, ...,\n",
       "           1.60190271e-04,  1.58167312e-04,  1.65454578e-04],\n",
       "         [-5.47958299e-06, -5.99351369e-06, -8.48985389e-06, ...,\n",
       "           1.08971986e-05,  1.42328292e-05,  2.33693376e-05],\n",
       "         ...,\n",
       "         [-1.11945843e-05, -1.49889737e-05, -1.40496282e-05, ...,\n",
       "           1.35773258e-05,  2.30966310e-05,  3.58438385e-05],\n",
       "         [ 3.20031770e-06, -4.16457335e-06, -7.07054092e-06, ...,\n",
       "           2.97596370e-05,  3.74389745e-05,  4.39112261e-05],\n",
       "         [-1.25956661e-05, -1.89161279e-05, -2.35922714e-05, ...,\n",
       "           1.00238816e-05,  1.84143033e-05,  3.29873900e-05]]),\n",
       "  'Stop'),\n",
       " (array([[ 2.36910756e-05,  2.27098128e-05,  2.90015379e-05, ...,\n",
       "           7.48036301e-06,  1.00587394e-05,  8.86146654e-06],\n",
       "         [-4.24265384e-06, -4.54899440e-06, -1.49289433e-06, ...,\n",
       "           4.55786575e-06,  9.72734113e-06,  8.04359942e-06],\n",
       "         [-1.88771607e-06, -2.53531086e-06,  5.38442565e-06, ...,\n",
       "           2.75342124e-06,  4.37439581e-06,  4.78669134e-07],\n",
       "         ...,\n",
       "         [-3.02097345e-05, -2.82391013e-05, -2.01110774e-05, ...,\n",
       "           5.00016171e-07,  2.71512982e-06, -5.25873204e-06],\n",
       "         [ 4.32992451e-06, -4.41306627e-07,  5.08390839e-07, ...,\n",
       "          -7.53894131e-07, -2.95624259e-06, -1.20620268e-05],\n",
       "         [-8.36518796e-05, -8.38352802e-05, -7.52479062e-05, ...,\n",
       "           2.02312322e-06,  4.47379621e-06, -3.89621165e-06]]),\n",
       "  'Open'),\n",
       " (array([[-2.97082098e-05, -4.30186239e-05, -5.31637127e-05, ...,\n",
       "          -5.91455342e-06, -4.55721841e-06, -3.65659561e-06],\n",
       "         [-1.19147680e-05, -1.98026651e-05, -2.88481185e-05, ...,\n",
       "          -7.96587821e-06, -6.86838879e-06, -3.45621008e-06],\n",
       "         [-1.11211328e-05, -2.55465700e-05, -4.27117750e-05, ...,\n",
       "          -1.52792410e-06, -3.53870464e-06, -3.68008355e-06],\n",
       "         ...,\n",
       "         [-2.53066537e-05, -3.06928717e-05, -4.36172164e-05, ...,\n",
       "           3.01604827e-06,  6.06520531e-06,  4.21759386e-06],\n",
       "         [-1.82162945e-05, -1.84903649e-05, -2.49334663e-05, ...,\n",
       "           1.69604568e-05,  1.98148554e-05,  1.95539947e-05],\n",
       "         [-2.98999046e-05, -3.53264283e-05, -4.66859662e-05, ...,\n",
       "          -3.39763419e-06,  2.70847640e-07,  9.03671975e-07]]),\n",
       "  'Close')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dispalying Segments for Participant 1:\n",
    "\n",
    "segments_participant_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating Sub Epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Create Sub-Epochs from Segments:\n",
    "\n",
    "def create_sub_epochs(segment, epoch_duration, sfreq):\n",
    "\n",
    "    n_samples_per_epoch = int(epoch_duration * sfreq)\n",
    "    n_epochs = segment.shape[1] // n_samples_per_epoch\n",
    "    sub_epochs = []\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        start_sample = i * n_samples_per_epoch\n",
    "        end_sample = start_sample + n_samples_per_epoch\n",
    "        sub_epoch = segment[:, start_sample:end_sample]\n",
    "        sub_epochs.append(sub_epoch)\n",
    "    \n",
    "    return sub_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Sub-Epoch Duration:\n",
    "\n",
    "sub_epoch_duration = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Sub-Epochs for each Individual Participant Part 1:\n",
    "\n",
    "# Create sub-epochs for Participant 1\n",
    "sub_epochs_participant_1 = []\n",
    "for segment, label in segments_participant_1:\n",
    "    sub_epochs = create_sub_epochs(segment, sub_epoch_duration, sfreq_participant_1)\n",
    "    sub_epochs_participant_1.extend([(sub_epoch, label) for sub_epoch in sub_epochs])\n",
    "\n",
    "# Create sub-epochs for Participant 2\n",
    "sub_epochs_participant_2 = []\n",
    "for segment, label in segments_participant_2:\n",
    "    sub_epochs = create_sub_epochs(segment, sub_epoch_duration, sfreq_participant_2)\n",
    "    sub_epochs_participant_2.extend([(sub_epoch, label) for sub_epoch in sub_epochs])\n",
    "\n",
    "# Create sub-epochs for Participant 3\n",
    "sub_epochs_participant_3 = []\n",
    "for segment, label in segments_participant_3:\n",
    "    sub_epochs = create_sub_epochs(segment, sub_epoch_duration, sfreq_participant_3)\n",
    "    sub_epochs_participant_3.extend([(sub_epoch, label) for sub_epoch in sub_epochs])\n",
    "\n",
    "# Create sub-epochs for Participant 4\n",
    "sub_epochs_participant_4 = []\n",
    "for segment, label in segments_participant_4:\n",
    "    sub_epochs = create_sub_epochs(segment, sub_epoch_duration, sfreq_participant_4)\n",
    "    sub_epochs_participant_4.extend([(sub_epoch, label) for sub_epoch in sub_epochs])\n",
    "\n",
    "# Create sub-epochs for Participant 5\n",
    "sub_epochs_participant_5 = []\n",
    "for segment, label in segments_participant_5:\n",
    "    sub_epochs = create_sub_epochs(segment, sub_epoch_duration, sfreq_participant_5)\n",
    "    sub_epochs_participant_5.extend([(sub_epoch, label) for sub_epoch in sub_epochs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Sub-Epochs for each Individual Participant Part 2:\n",
    "\n",
    "# Create sub-epochs for Participant 6\n",
    "sub_epochs_participant_6 = []\n",
    "for segment, label in segments_participant_6:\n",
    "    sub_epochs = create_sub_epochs(segment, sub_epoch_duration, sfreq_participant_6)\n",
    "    sub_epochs_participant_6.extend([(sub_epoch, label) for sub_epoch in sub_epochs])\n",
    "\n",
    "# Create sub-epochs for Participant 7\n",
    "sub_epochs_participant_7 = []\n",
    "for segment, label in segments_participant_7:\n",
    "    sub_epochs = create_sub_epochs(segment, sub_epoch_duration, sfreq_participant_7)\n",
    "    sub_epochs_participant_7.extend([(sub_epoch, label) for sub_epoch in sub_epochs])\n",
    "\n",
    "# Create sub-epochs for Participant 8\n",
    "sub_epochs_participant_8 = []\n",
    "for segment, label in segments_participant_8:\n",
    "    sub_epochs = create_sub_epochs(segment, sub_epoch_duration, sfreq_participant_8)\n",
    "    sub_epochs_participant_8.extend([(sub_epoch, label) for sub_epoch in sub_epochs])\n",
    "\n",
    "# Create sub-epochs for Participant 9\n",
    "sub_epochs_participant_9 = []\n",
    "for segment, label in segments_participant_9:\n",
    "    sub_epochs = create_sub_epochs(segment, sub_epoch_duration, sfreq_participant_9)\n",
    "    sub_epochs_participant_9.extend([(sub_epoch, label) for sub_epoch in sub_epochs])\n",
    "\n",
    "# Create sub-epochs for Participant 10\n",
    "sub_epochs_participant_10 = []\n",
    "for segment, label in segments_participant_10:\n",
    "    sub_epochs = create_sub_epochs(segment, sub_epoch_duration, sfreq_participant_10)\n",
    "    sub_epochs_participant_10.extend([(sub_epoch, label) for sub_epoch in sub_epochs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Sub-Epochs for each Individual Participant Part 3:\n",
    "\n",
    "# Create sub-epochs for Participant 11\n",
    "sub_epochs_participant_11 = []\n",
    "for segment, label in segments_participant_11:\n",
    "    sub_epochs = create_sub_epochs(segment, sub_epoch_duration, sfreq_participant_11)\n",
    "    sub_epochs_participant_11.extend([(sub_epoch, label) for sub_epoch in sub_epochs])\n",
    "\n",
    "# Create sub-epochs for Participant 12\n",
    "sub_epochs_participant_12 = []\n",
    "for segment, label in segments_participant_12:\n",
    "    sub_epochs = create_sub_epochs(segment, sub_epoch_duration, sfreq_participant_12)\n",
    "    sub_epochs_participant_12.extend([(sub_epoch, label) for sub_epoch in sub_epochs])\n",
    "\n",
    "# Create sub-epochs for Participant 13\n",
    "sub_epochs_participant_13 = []\n",
    "for segment, label in segments_participant_13:\n",
    "    sub_epochs = create_sub_epochs(segment, sub_epoch_duration, sfreq_participant_13)\n",
    "    sub_epochs_participant_13.extend([(sub_epoch, label) for sub_epoch in sub_epochs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Sub-Epoch Data into DataFrames:\n",
    "\n",
    "data_sub_epochs_participant_1 = pd.DataFrame([(label, sub_epoch) for sub_epoch, label in sub_epochs_participant_1], columns=['Label', 'Sub_Epoch'])\n",
    "data_sub_epochs_participant_2 = pd.DataFrame([(label, sub_epoch) for sub_epoch, label in sub_epochs_participant_2], columns=['Label', 'Sub_Epoch'])\n",
    "data_sub_epochs_participant_3 = pd.DataFrame([(label, sub_epoch) for sub_epoch, label in sub_epochs_participant_3], columns=['Label', 'Sub_Epoch'])\n",
    "data_sub_epochs_participant_4 = pd.DataFrame([(label, sub_epoch) for sub_epoch, label in sub_epochs_participant_4], columns=['Label', 'Sub_Epoch'])\n",
    "data_sub_epochs_participant_5 = pd.DataFrame([(label, sub_epoch) for sub_epoch, label in sub_epochs_participant_5], columns=['Label', 'Sub_Epoch'])\n",
    "data_sub_epochs_participant_6 = pd.DataFrame([(label, sub_epoch) for sub_epoch, label in sub_epochs_participant_6], columns=['Label', 'Sub_Epoch'])\n",
    "data_sub_epochs_participant_7 = pd.DataFrame([(label, sub_epoch) for sub_epoch, label in sub_epochs_participant_7], columns=['Label', 'Sub_Epoch'])\n",
    "data_sub_epochs_participant_8 = pd.DataFrame([(label, sub_epoch) for sub_epoch, label in sub_epochs_participant_8], columns=['Label', 'Sub_Epoch'])\n",
    "data_sub_epochs_participant_9 = pd.DataFrame([(label, sub_epoch) for sub_epoch, label in sub_epochs_participant_9], columns=['Label', 'Sub_Epoch'])\n",
    "data_sub_epochs_participant_10 = pd.DataFrame([(label, sub_epoch) for sub_epoch, label in sub_epochs_participant_10], columns=['Label', 'Sub_Epoch'])\n",
    "data_sub_epochs_participant_11 = pd.DataFrame([(label, sub_epoch) for sub_epoch, label in sub_epochs_participant_11], columns=['Label', 'Sub_Epoch'])\n",
    "data_sub_epochs_participant_12 = pd.DataFrame([(label, sub_epoch) for sub_epoch, label in sub_epochs_participant_12], columns=['Label', 'Sub_Epoch'])\n",
    "data_sub_epochs_participant_13 = pd.DataFrame([(label, sub_epoch) for sub_epoch, label in sub_epochs_participant_13], columns=['Label', 'Sub_Epoch'])\n",
    "\n",
    "\n",
    "# Save Sub-Epoch Data to CSV files for Verification:\n",
    "\n",
    "data_sub_epochs_participant_1.to_csv('Data/SubEpochData/Participant_1_Sub_Epoch_Data.csv', index = False)\n",
    "data_sub_epochs_participant_2.to_csv('Data/SubEpochData/Participant_2_Sub_Epoch_Data.csv', index = False)\n",
    "data_sub_epochs_participant_3.to_csv('Data/SubEpochData/Participant_3_Sub_Epoch_Data.csv', index = False)\n",
    "data_sub_epochs_participant_4.to_csv('Data/SubEpochData/Participant_4_Sub_Epoch_Data.csv', index = False)\n",
    "data_sub_epochs_participant_5.to_csv('Data/SubEpochData/Participant_5_Sub_Epoch_Data.csv', index = False)\n",
    "data_sub_epochs_participant_6.to_csv('Data/SubEpochData/Participant_6_Sub_Epoch_Data.csv', index = False)\n",
    "data_sub_epochs_participant_7.to_csv('Data/SubEpochData/Participant_7_Sub_Epoch_Data.csv', index = False)\n",
    "data_sub_epochs_participant_8.to_csv('Data/SubEpochData/Participant_8_Sub_Epoch_Data.csv', index = False)\n",
    "data_sub_epochs_participant_9.to_csv('Data/SubEpochData/Participant_9_Sub_Epoch_Data.csv', index = False)\n",
    "data_sub_epochs_participant_10.to_csv('Data/SubEpochData/Participant_10_Sub_Epoch_Data.csv', index = False)\n",
    "data_sub_epochs_participant_11.to_csv('Data/SubEpochData/Participant_11_Sub_Epoch_Data.csv', index = False)\n",
    "data_sub_epochs_participant_12.to_csv('Data/SubEpochData/Participant_12_Sub_Epoch_Data.csv', index = False)\n",
    "data_sub_epochs_participant_13.to_csv('Data/SubEpochData/Participant_13_Sub_Epoch_Data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant 1 Sub-Epoch Data:\n",
      "  Label                                          Sub_Epoch\n",
      "0     I  [[0.00021323827937150136, 0.000205378181898957...\n",
      "1     I  [[6.528388254172846e-05, 6.793395112452262e-05...\n",
      "2     I  [[-1.197846936741574e-05, -1.5899529935307284e...\n",
      "3     I  [[1.62035004669331e-05, 1.534839092153962e-05,...\n",
      "4     I  [[1.908828371455047e-06, -9.281953529624032e-0...\n"
     ]
    }
   ],
   "source": [
    "# Display the Sub-Epoch Data for Verification:\n",
    "\n",
    "print(\"Participant 1 Sub-Epoch Data:\")\n",
    "print(data_sub_epochs_participant_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constructing Final Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Sub-Epoch Data from all Participants into a Single Dataset:\n",
    "\n",
    "concatenated_sub_epoch_dataset = pd.concat([data_sub_epochs_participant_1, \n",
    "                                            data_sub_epochs_participant_2, \n",
    "                                            data_sub_epochs_participant_3,\n",
    "                                            data_sub_epochs_participant_4,\n",
    "                                            data_sub_epochs_participant_5,\n",
    "                                            data_sub_epochs_participant_6,\n",
    "                                            data_sub_epochs_participant_7,\n",
    "                                            data_sub_epochs_participant_8,\n",
    "                                            data_sub_epochs_participant_9,\n",
    "                                            data_sub_epochs_participant_10,\n",
    "                                            data_sub_epochs_participant_11,\n",
    "                                            data_sub_epochs_participant_12,\n",
    "                                            data_sub_epochs_participant_13]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Sub-Epoch Data (first few rows):\n",
      "  Label                                          Sub_Epoch\n",
      "0     I  [[0.00021323827937150136, 0.000205378181898957...\n",
      "1     I  [[6.528388254172846e-05, 6.793395112452262e-05...\n",
      "2     I  [[-1.197846936741574e-05, -1.5899529935307284e...\n",
      "3     I  [[1.62035004669331e-05, 1.534839092153962e-05,...\n",
      "4     I  [[1.908828371455047e-06, -9.281953529624032e-0...\n"
     ]
    }
   ],
   "source": [
    "# Check the First few rows to ensure the Concatenation was Successful:\n",
    "print(\"Combined Sub-Epoch Data (first few rows):\")\n",
    "print(concatenated_sub_epoch_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Combined Dataset to CSV:\n",
    "\n",
    "concatenated_sub_epoch_dataset.to_csv('Data/FinalDataset/Combined_Sub_Epoch_Final_Dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Extract Power Spectral Density (PSD) Features:\n",
    "\n",
    "def extract_psd_features(epochs, bands, sfreq):\n",
    "\n",
    "    psd_features = []\n",
    "    logging.info(f\"Extracting PSD Features for {len(epochs)} epochs.\")\n",
    "\n",
    "    for epoch, label in epochs:\n",
    "        psd, freqs = mne.time_frequency.psd_array_multitaper(epoch, sfreq = sfreq, fmin = 0.5, fmax = 30)\n",
    "        band_powers = {'Label': label}\n",
    "\n",
    "        for band, (low, high) in bands.items():\n",
    "            band_power = np.mean(psd[:, (freqs >= low) & (freqs <= high)], axis = 1)\n",
    "\n",
    "            for i, power in enumerate(band_power):\n",
    "                band_powers[f'{band}_ch{i}'] = power\n",
    "\n",
    "        psd_features.append(band_powers)\n",
    "\n",
    "    logging.info(f\"\\nPSD Features Extracted: {psd_features[0].keys()}\")\n",
    "    return pd.DataFrame(psd_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Extract Wavelet Transform Features:\n",
    "\n",
    "def extract_wavelet_features(epochs, wavelet = 'db4', level = 5):\n",
    "\n",
    "    wavelet_features = []\n",
    "    logging.info(f\"Extracting Wavelet Features for {len(epochs)} epochs.\")\n",
    "\n",
    "    for epoch, label in epochs:\n",
    "        features = {'Label': label}\n",
    "\n",
    "        for ch in range(epoch.shape[0]):\n",
    "            coeffs = pywt.wavedec(epoch[ch], wavelet, level = level)\n",
    "\n",
    "            for i, coeff in enumerate(coeffs):\n",
    "                features[f'ch{ch}_coeff{i}_mean'] = np.mean(coeff)\n",
    "                features[f'ch{ch}_coeff{i}_std'] = np.std(coeff)\n",
    "\n",
    "        wavelet_features.append(features)\n",
    "\n",
    "    logging.info(f\"\\nWavelet Features Extracted: {wavelet_features[0].keys()}\")\n",
    "    return pd.DataFrame(wavelet_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-06 15:32:54,654 - INFO - Extracting PSD Features for 3900 epochs.\n",
      "2024-07-06 15:32:58,347 - INFO - \n",
      "PSD Features Extracted: dict_keys(['Label', 'delta_ch0', 'delta_ch1', 'delta_ch2', 'delta_ch3', 'delta_ch4', 'delta_ch5', 'delta_ch6', 'delta_ch7', 'delta_ch8', 'delta_ch9', 'delta_ch10', 'delta_ch11', 'delta_ch12', 'delta_ch13', 'theta_ch0', 'theta_ch1', 'theta_ch2', 'theta_ch3', 'theta_ch4', 'theta_ch5', 'theta_ch6', 'theta_ch7', 'theta_ch8', 'theta_ch9', 'theta_ch10', 'theta_ch11', 'theta_ch12', 'theta_ch13', 'alpha_ch0', 'alpha_ch1', 'alpha_ch2', 'alpha_ch3', 'alpha_ch4', 'alpha_ch5', 'alpha_ch6', 'alpha_ch7', 'alpha_ch8', 'alpha_ch9', 'alpha_ch10', 'alpha_ch11', 'alpha_ch12', 'alpha_ch13', 'beta_ch0', 'beta_ch1', 'beta_ch2', 'beta_ch3', 'beta_ch4', 'beta_ch5', 'beta_ch6', 'beta_ch7', 'beta_ch8', 'beta_ch9', 'beta_ch10', 'beta_ch11', 'beta_ch12', 'beta_ch13', 'gamma_ch0', 'gamma_ch1', 'gamma_ch2', 'gamma_ch3', 'gamma_ch4', 'gamma_ch5', 'gamma_ch6', 'gamma_ch7', 'gamma_ch8', 'gamma_ch9', 'gamma_ch10', 'gamma_ch11', 'gamma_ch12', 'gamma_ch13'])\n",
      "2024-07-06 15:32:58,384 - INFO - \n",
      "PSD features DataFrame shape: (3900, 71)\n",
      "2024-07-06 15:32:58,385 - INFO - Extracting Wavelet Features for 3900 epochs.\n",
      "2024-07-06 15:33:03,491 - INFO - \n",
      "Wavelet Features Extracted: dict_keys(['Label', 'ch0_coeff0_mean', 'ch0_coeff0_std', 'ch0_coeff1_mean', 'ch0_coeff1_std', 'ch0_coeff2_mean', 'ch0_coeff2_std', 'ch0_coeff3_mean', 'ch0_coeff3_std', 'ch0_coeff4_mean', 'ch0_coeff4_std', 'ch0_coeff5_mean', 'ch0_coeff5_std', 'ch1_coeff0_mean', 'ch1_coeff0_std', 'ch1_coeff1_mean', 'ch1_coeff1_std', 'ch1_coeff2_mean', 'ch1_coeff2_std', 'ch1_coeff3_mean', 'ch1_coeff3_std', 'ch1_coeff4_mean', 'ch1_coeff4_std', 'ch1_coeff5_mean', 'ch1_coeff5_std', 'ch2_coeff0_mean', 'ch2_coeff0_std', 'ch2_coeff1_mean', 'ch2_coeff1_std', 'ch2_coeff2_mean', 'ch2_coeff2_std', 'ch2_coeff3_mean', 'ch2_coeff3_std', 'ch2_coeff4_mean', 'ch2_coeff4_std', 'ch2_coeff5_mean', 'ch2_coeff5_std', 'ch3_coeff0_mean', 'ch3_coeff0_std', 'ch3_coeff1_mean', 'ch3_coeff1_std', 'ch3_coeff2_mean', 'ch3_coeff2_std', 'ch3_coeff3_mean', 'ch3_coeff3_std', 'ch3_coeff4_mean', 'ch3_coeff4_std', 'ch3_coeff5_mean', 'ch3_coeff5_std', 'ch4_coeff0_mean', 'ch4_coeff0_std', 'ch4_coeff1_mean', 'ch4_coeff1_std', 'ch4_coeff2_mean', 'ch4_coeff2_std', 'ch4_coeff3_mean', 'ch4_coeff3_std', 'ch4_coeff4_mean', 'ch4_coeff4_std', 'ch4_coeff5_mean', 'ch4_coeff5_std', 'ch5_coeff0_mean', 'ch5_coeff0_std', 'ch5_coeff1_mean', 'ch5_coeff1_std', 'ch5_coeff2_mean', 'ch5_coeff2_std', 'ch5_coeff3_mean', 'ch5_coeff3_std', 'ch5_coeff4_mean', 'ch5_coeff4_std', 'ch5_coeff5_mean', 'ch5_coeff5_std', 'ch6_coeff0_mean', 'ch6_coeff0_std', 'ch6_coeff1_mean', 'ch6_coeff1_std', 'ch6_coeff2_mean', 'ch6_coeff2_std', 'ch6_coeff3_mean', 'ch6_coeff3_std', 'ch6_coeff4_mean', 'ch6_coeff4_std', 'ch6_coeff5_mean', 'ch6_coeff5_std', 'ch7_coeff0_mean', 'ch7_coeff0_std', 'ch7_coeff1_mean', 'ch7_coeff1_std', 'ch7_coeff2_mean', 'ch7_coeff2_std', 'ch7_coeff3_mean', 'ch7_coeff3_std', 'ch7_coeff4_mean', 'ch7_coeff4_std', 'ch7_coeff5_mean', 'ch7_coeff5_std', 'ch8_coeff0_mean', 'ch8_coeff0_std', 'ch8_coeff1_mean', 'ch8_coeff1_std', 'ch8_coeff2_mean', 'ch8_coeff2_std', 'ch8_coeff3_mean', 'ch8_coeff3_std', 'ch8_coeff4_mean', 'ch8_coeff4_std', 'ch8_coeff5_mean', 'ch8_coeff5_std', 'ch9_coeff0_mean', 'ch9_coeff0_std', 'ch9_coeff1_mean', 'ch9_coeff1_std', 'ch9_coeff2_mean', 'ch9_coeff2_std', 'ch9_coeff3_mean', 'ch9_coeff3_std', 'ch9_coeff4_mean', 'ch9_coeff4_std', 'ch9_coeff5_mean', 'ch9_coeff5_std', 'ch10_coeff0_mean', 'ch10_coeff0_std', 'ch10_coeff1_mean', 'ch10_coeff1_std', 'ch10_coeff2_mean', 'ch10_coeff2_std', 'ch10_coeff3_mean', 'ch10_coeff3_std', 'ch10_coeff4_mean', 'ch10_coeff4_std', 'ch10_coeff5_mean', 'ch10_coeff5_std', 'ch11_coeff0_mean', 'ch11_coeff0_std', 'ch11_coeff1_mean', 'ch11_coeff1_std', 'ch11_coeff2_mean', 'ch11_coeff2_std', 'ch11_coeff3_mean', 'ch11_coeff3_std', 'ch11_coeff4_mean', 'ch11_coeff4_std', 'ch11_coeff5_mean', 'ch11_coeff5_std', 'ch12_coeff0_mean', 'ch12_coeff0_std', 'ch12_coeff1_mean', 'ch12_coeff1_std', 'ch12_coeff2_mean', 'ch12_coeff2_std', 'ch12_coeff3_mean', 'ch12_coeff3_std', 'ch12_coeff4_mean', 'ch12_coeff4_std', 'ch12_coeff5_mean', 'ch12_coeff5_std', 'ch13_coeff0_mean', 'ch13_coeff0_std', 'ch13_coeff1_mean', 'ch13_coeff1_std', 'ch13_coeff2_mean', 'ch13_coeff2_std', 'ch13_coeff3_mean', 'ch13_coeff3_std', 'ch13_coeff4_mean', 'ch13_coeff4_std', 'ch13_coeff5_mean', 'ch13_coeff5_std'])\n",
      "2024-07-06 15:33:03,605 - INFO - \n",
      "Wavelet features DataFrame Shape: (3900, 169)\n",
      "2024-07-06 15:33:04,449 - INFO - \n",
      "Combined features DataFrame shape: (1521000, 239)\n",
      "2024-07-06 15:33:05,796 - INFO - \n",
      "Combined features DataFrame shape after dropping duplicates: (1521000, 239)\n",
      "2024-07-06 15:37:22,741 - INFO - \n",
      "Final combined features saved. Number of features: 239\n"
     ]
    }
   ],
   "source": [
    "# Defining Frequency bands for PSD:\n",
    "\n",
    "bands = {\n",
    "    'delta': (0.5, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 12),\n",
    "    'beta': (12, 30),\n",
    "    'gamma': (31, 50)\n",
    "}\n",
    "\n",
    "# Combine all participants' sub-epochs:\n",
    "all_sub_epochs = (sub_epochs_participant_1 + sub_epochs_participant_2 + sub_epochs_participant_3 + sub_epochs_participant_4 + sub_epochs_participant_5 + sub_epochs_participant_6 + sub_epochs_participant_7 + sub_epochs_participant_8 + sub_epochs_participant_9 + sub_epochs_participant_10 + sub_epochs_participant_11 + sub_epochs_participant_12 + sub_epochs_participant_13)\n",
    "\n",
    "# Extract PSD Features:\n",
    "psd_features = extract_psd_features(all_sub_epochs, bands, sfreq_participant_1)\n",
    "logging.info(f\"\\nPSD features DataFrame shape: {psd_features.shape}\")\n",
    "\n",
    "# Extract Wavelet Features:\n",
    "wavelet_features = extract_wavelet_features(all_sub_epochs)\n",
    "logging.info(f\"\\nWavelet features DataFrame Shape: {wavelet_features.shape}\")\n",
    "\n",
    "# Combine Features:\n",
    "combined_features = pd.merge(psd_features, wavelet_features, on = 'Label')\n",
    "logging.info(f\"\\nCombined features DataFrame shape: {combined_features.shape}\")\n",
    "\n",
    "# Drop Duplicate Features:\n",
    "combined_features = combined_features.loc[:,~combined_features.columns.duplicated()]\n",
    "logging.info(f\"\\nCombined features DataFrame shape after dropping duplicates: {combined_features.shape}\")\n",
    "\n",
    "# Save combined features to CSV\n",
    "combined_features.to_csv('Data/FinalDataset/Full_Final_Dataset.csv', index = False)\n",
    "logging.info(f\"\\nFinal combined features saved. Number of features: {combined_features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Features:\n",
      "  Label     delta_ch0     delta_ch1     delta_ch2     delta_ch3     delta_ch4  \\\n",
      "0     I  2.342114e-07  1.001417e-07  1.727662e-07  1.656557e-07  1.231673e-07   \n",
      "1     I  2.342114e-07  1.001417e-07  1.727662e-07  1.656557e-07  1.231673e-07   \n",
      "2     I  2.342114e-07  1.001417e-07  1.727662e-07  1.656557e-07  1.231673e-07   \n",
      "3     I  2.342114e-07  1.001417e-07  1.727662e-07  1.656557e-07  1.231673e-07   \n",
      "4     I  2.342114e-07  1.001417e-07  1.727662e-07  1.656557e-07  1.231673e-07   \n",
      "\n",
      "      delta_ch5     delta_ch6     delta_ch7     delta_ch8  ...  \\\n",
      "0  1.318333e-07  1.307850e-07  1.548563e-07  1.369585e-07  ...   \n",
      "1  1.318333e-07  1.307850e-07  1.548563e-07  1.369585e-07  ...   \n",
      "2  1.318333e-07  1.307850e-07  1.548563e-07  1.369585e-07  ...   \n",
      "3  1.318333e-07  1.307850e-07  1.548563e-07  1.369585e-07  ...   \n",
      "4  1.318333e-07  1.307850e-07  1.548563e-07  1.369585e-07  ...   \n",
      "\n",
      "   ch13_coeff1_mean  ch13_coeff1_std  ch13_coeff2_mean  ch13_coeff2_std  \\\n",
      "0          0.000001         0.000064          0.000004         0.000019   \n",
      "1         -0.000002         0.000044          0.000008         0.000029   \n",
      "2         -0.000005         0.000029         -0.000001         0.000023   \n",
      "3          0.000006         0.000034          0.000005         0.000024   \n",
      "4          0.000011         0.000054          0.000003         0.000042   \n",
      "\n",
      "   ch13_coeff3_mean  ch13_coeff3_std  ch13_coeff4_mean  ch13_coeff4_std  \\\n",
      "0         -0.000002         0.000031     -2.154827e-07         0.000015   \n",
      "1         -0.000002         0.000029     -2.776257e-07         0.000014   \n",
      "2          0.000004         0.000025     -1.300916e-06         0.000013   \n",
      "3          0.000002         0.000023     -1.263493e-06         0.000013   \n",
      "4          0.000003         0.000031      9.822161e-07         0.000013   \n",
      "\n",
      "   ch13_coeff5_mean  ch13_coeff5_std  \n",
      "0     -2.338833e-08         0.000003  \n",
      "1     -4.806514e-10         0.000003  \n",
      "2      1.157226e-08         0.000004  \n",
      "3      5.174178e-09         0.000003  \n",
      "4     -2.273509e-08         0.000003  \n",
      "\n",
      "[5 rows x 239 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the Extracted Features:\n",
    "\n",
    "print(\"Extracted Features:\")\n",
    "print(combined_features.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
