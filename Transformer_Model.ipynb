{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Libraries:\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "from scipy.signal import welch, stft\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_curve, roc_auc_score, average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import matthews_corrcoef, cohen_kappa_score\n",
    "from itertools import cycle\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining File Paths:\n",
    "\n",
    "file_participant_1 = 'Data/Participant_1.edf'\n",
    "file_participant_2 = 'Data/Participant_2.edf'\n",
    "file_participant_3 = 'Data/Participant_3.edf'\n",
    "file_participant_4 = 'Data/Participant_4.edf'\n",
    "file_participant_5 = 'Data/Participant_5.edf'\n",
    "file_participant_6 = 'Data/Participant_6.edf'\n",
    "file_participant_7 = 'Data/Participant_7.edf'\n",
    "file_participant_8 = 'Data/Participant_8.edf'\n",
    "file_participant_9 = 'Data/Participant_9.edf'\n",
    "file_participant_10 = 'Data/Participant_10.edf'\n",
    "file_participant_11 = 'Data/Participant_11.edf'\n",
    "file_participant_12 = 'Data/Participant_12.edf'\n",
    "file_participant_13 = 'Data/Participant_13.edf'\n",
    "\n",
    "edf_data_files = [\n",
    "    file_participant_1,\n",
    "    file_participant_2,\n",
    "    file_participant_3,\n",
    "    file_participant_4,\n",
    "    file_participant_5,\n",
    "    file_participant_6,\n",
    "    file_participant_7,\n",
    "    file_participant_8,\n",
    "    file_participant_9,\n",
    "    file_participant_10,\n",
    "    file_participant_11,\n",
    "    file_participant_12,\n",
    "    file_participant_13\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Start, Finish and Breaks:\n",
    "\n",
    "# Loading the first file to use as a reference for channel names:\n",
    "reference_raw = mne.io.read_raw_edf(edf_data_files[0], preload = True)\n",
    "reference_channels = reference_raw.info['ch_names']\n",
    "\n",
    "raw_objects = []\n",
    "\n",
    "# Define the segments of interest in seconds:\n",
    "segments = [\n",
    "    (30, 90),  # \"I\"\n",
    "    (120, 180),  # \"Yes\"\n",
    "    (210, 270),  # \"No\"\n",
    "    (300, 360),  # \"Want\"\n",
    "    (390, 450),  # \"Help\"\n",
    "    (480, 540),  # \"More\"\n",
    "    (570, 630),  # \"That\"\n",
    "    (660, 720),  # \"Stop\"\n",
    "    (750, 810),  # \"Open\"\n",
    "    (840, 900)   # \"Close\"\n",
    "]\n",
    "\n",
    "for file_path in edf_data_files:\n",
    "    print(f\"Editing file: {file_path}...\")\n",
    "    raw = mne.io.read_raw_edf(file_path, preload = True)\n",
    "    raw.pick_channels(reference_channels)\n",
    "    \n",
    "    # Create an empty list to store the segments:\n",
    "    data_segments = []\n",
    "    \n",
    "    for start, end in segments:\n",
    "        segment = raw.copy().crop(tmin=start, tmax=end)\n",
    "        data_segments.append(segment)\n",
    "    \n",
    "    # Concatenate the segments:\n",
    "    raw_concatenated = mne.concatenate_raws(data_segments)\n",
    "    raw_objects.append(raw_concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the Resulting Files after Segmentation:\n",
    "\n",
    "raw_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating all Loaded and Processed Files:\n",
    "\n",
    "raw = mne.concatenate_raws(raw_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Preprocess Raw Data:\n",
    "\n",
    "def preprocess_raw_data(raw):\n",
    "\n",
    "    print(\"STARTING PREPROCESSING: \")\n",
    "\n",
    "    # Handling NaNs: Replace NaNs with the mean of the respective channel:\n",
    "    raw_data = raw.get_data()\n",
    "\n",
    "    for i in range(raw_data.shape[0]):\n",
    "        nan_indices = np.isnan(raw_data[i])\n",
    "\n",
    "        if np.any(nan_indices):\n",
    "            mean_value = np.nanmean(raw_data[i])\n",
    "            raw_data[i, nan_indices] = mean_value\n",
    "\n",
    "    raw._data = raw_data\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Filtering: Bandpass filter between 0.5-30 Hz:\n",
    "    raw.filter(0.5, 30., fir_design = 'firwin')\n",
    "\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Artifact Removal: Independent Component Analysis (ICA):\n",
    "    ica = mne.preprocessing.ICA(n_components = 14, random_state = 97, max_iter = 800)\n",
    "    ica.fit(raw)\n",
    "    raw = ica.apply(raw)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Spatial Filtering: Common Average Reference (CAR):\n",
    "    raw.set_eeg_reference('average', projection = True)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Channel Interpolation: Interpolate bad channels\n",
    "    raw.interpolate_bads()\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Baseline Correction: Apply baseline correction using the mean of the segment\n",
    "    raw.apply_function(lambda x: x - np.mean(x), picks = 'eeg')\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"PREPROCESSING DONE!\")\n",
    "    \n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the Raw Data:\n",
    "\n",
    "raw = preprocess_raw_data(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Fixed-Length Epochs:\n",
    "\n",
    "epoch_duration = 60  # seconds\n",
    "start_times = np.arange(0, raw.times[-1] - epoch_duration, epoch_duration)\n",
    "end_times = start_times + epoch_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying Epoch Start and End Times:\n",
    "\n",
    "print(\"Start Times: \", start_times)\n",
    "print(\"\\nTotal Number of Start Times: \", len(start_times))\n",
    "print(\"\\n\")\n",
    "print(\"End Times: \", end_times)\n",
    "print(\"\\nTotal Number of End Times: \", len(end_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Words:\n",
    "\n",
    "words = ['I', 'Yes', 'No', 'Want', 'Help', 'More', 'That', 'Stop', 'Open', 'Close']\n",
    "print(\"Words: \", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Frequency:\n",
    "\n",
    "sfreq = raw.info['sfreq']\n",
    "print(\"Frequency Across Channels: \", sfreq, \"Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction Function:\n",
    "\n",
    "def extract_features(epoch_data, sfreq):\n",
    "\n",
    "    # Calculating Statistical Features:\n",
    "    mean_vals = np.mean(epoch_data, axis = 1) # Mean value of the signal for each channel.\n",
    "    std_vals = np.std(epoch_data, axis = 1) # Standard deviation of the signal for each channel.\n",
    "    skew_vals = skew(epoch_data, axis = 1) # Skewness of the signal for each channel, indicating asymmetry.\n",
    "    kurt_vals = kurtosis(epoch_data, axis = 1) # Kurtosis of the signal for each channel, indicating peakedness.\n",
    "\n",
    "    # Power Spectral Density (PSD) Features:\n",
    "    freqs, psd = welch(epoch_data, sfreq, nperseg = int(sfreq)) # Computes the PSD using Welchâ€™s method.\n",
    "    # Average power in the theta (4-8 Hz), alpha (8-12 Hz), and beta (12-30 Hz) frequency bands:\n",
    "    theta_power = psd[:, (freqs > 4) & (freqs <= 8)].mean(axis = 1)\n",
    "    alpha_power = psd[:, (freqs > 8) & (freqs <= 12)].mean(axis = 1)\n",
    "    beta_power = psd[:, (freqs > 12) & (freqs <= 30)].mean(axis = 1)\n",
    "\n",
    "    # Short-Time Fourier Transform (STFT) Features:\n",
    "    _, _, Zxx = stft(epoch_data, fs = sfreq, nperseg = int(sfreq/2)) # Computes the STFT, which provides time-frequency representation of the signal.\n",
    "    stft_power = np.abs(Zxx).mean(axis = 2) # Mean power from the STFT representation, averaged over time.\n",
    "    \n",
    "    # Entropy Feature:\n",
    "    entropy_vals = np.array([entropy(np.abs(epoch_data[channel, :])) for channel in range(epoch_data.shape[0])]) # Computes the entropy of the signal for each channel, indicating the complexity or randomness of the signal.\n",
    "\n",
    "    # Combining Features:\n",
    "    features = np.stack([\n",
    "        mean_vals,\n",
    "        std_vals,\n",
    "        skew_vals,\n",
    "        kurt_vals,\n",
    "        theta_power,\n",
    "        alpha_power,\n",
    "        beta_power,\n",
    "        stft_power.mean(axis = 1),\n",
    "        entropy_vals\n",
    "    ], axis = 1) # Combines all extracted features into a single array with each feature as a column.\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmenting the Data into Epochs and Sub-Epochs:\n",
    "# First -> 60 second epochs.\n",
    "# Second -> 2 second sub-epochs.\n",
    "# Third -> Extracting Features.\n",
    "\n",
    "labeled_features_data = []\n",
    "sub_epoch_duration = 2  # seconds\n",
    "\n",
    "for i, (start, end) in enumerate(zip(start_times, end_times)): # Loops through each 30-second epoch:\n",
    "    start_sample = int(start * sfreq)\n",
    "    end_sample = int(end * sfreq)\n",
    "    epoch_data, _ = raw[:, start_sample:end_sample] # Extracts the EEG data for the current epoch.\n",
    "    word_label = words[i % len(words)] # Assigns a label to the current epoch using a list of predefined words.\n",
    "    \n",
    "    for j in range(int(epoch_duration / sub_epoch_duration)): # Iterate over Sub-Epochs:\n",
    "        sub_start = j * sub_epoch_duration * int(sfreq)\n",
    "        sub_end = (j + 1) * sub_epoch_duration * int(sfreq)\n",
    "        sub_epoch_data = epoch_data[:, sub_start:sub_end]\n",
    "        \n",
    "        # Calls the extract_features function to extract from sub-epoch:\n",
    "        features = extract_features(sub_epoch_data, sfreq)\n",
    "        labeled_features_data.append((features, word_label)) # Stores the extracted features along with the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Features and Labels:\n",
    "\n",
    "features = np.array([f[0] for f in labeled_features_data])\n",
    "labels = np.array([f[1] for f in labeled_features_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Data - Flattening & Scaling:\n",
    "\n",
    "# Flattening the last two dimensions of the features array:\n",
    "# To transform the 3D feature array into a 2D array where each row represents a single sample and each column represents a feature.\n",
    "features_2d = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Scaling the features:\n",
    "# To standardise the features by scaling them so that they have a mean of 0 and a standard deviation of 1.\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set Preperation:\n",
    "\n",
    "# Principal Component Analysis:\n",
    "pca = PCA(n_components = 0.95) \n",
    "features_pca = pca.fit_transform(features_scaled)\n",
    "\n",
    "# Mutual Information:\n",
    "num_sub_epochs_per_epoch = int(epoch_duration / sub_epoch_duration)\n",
    "total_sub_epochs = num_sub_epochs_per_epoch * len(start_times)\n",
    "\n",
    "num_features = features_scaled.shape[1]\n",
    "k_best = min(num_features, 20)  # Ensure k does not exceed the number of available features.\n",
    "mi_selector = SelectKBest(mutual_info_classif, k = k_best)\n",
    "features_mi = mi_selector.fit_transform(features_scaled, labels)\n",
    "\n",
    "selected_features = features_mi # Choosing feature set to use for further model training.\n",
    "\n",
    "num_features_mi = features_mi.shape[1]  # Number of features after MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train, Test and Validation Sets:\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    selected_features, labels, test_size = 0.3, random_state = 42, stratify = labels)\n",
    "\n",
    "val_features, test_features, val_labels, test_labels = train_test_split(\n",
    "    test_features, test_labels, test_size = 0.5, random_state = 42, stratify = test_labels)\n",
    "\n",
    "print(\"Total Dataset Size: \", (len(train_features) + len(val_features) + len(test_features)))\n",
    "print(\"\\n\")\n",
    "print(f\"Training Data Size: {len(train_features)}\")\n",
    "print(f\"Validation Data Size: {len(val_features)}\")\n",
    "print(f\"Testing Data Size: {len(test_features)}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Counting occurrences of each label in the training, validation, and testing sets\n",
    "train_label_counts = Counter(train_labels)\n",
    "val_label_counts = Counter(val_labels)\n",
    "test_label_counts = Counter(test_labels)\n",
    "\n",
    "# Calculating the total number of samples in each set\n",
    "total_train = len(train_labels)\n",
    "total_val = len(val_labels)\n",
    "total_test = len(test_labels)\n",
    "\n",
    "# Printing the distribution of each label in each set\n",
    "print(\"Training set label distribution:\")\n",
    "for label, count in train_label_counts.items():\n",
    "    print(f\"{label}: {count} ({count / total_train * 100:.2f}%)\")\n",
    "\n",
    "print(\"\\nValidation set label distribution:\")\n",
    "for label, count in val_label_counts.items():\n",
    "    print(f\"{label}: {count} ({count / total_val * 100:.2f}%)\")\n",
    "\n",
    "print(\"\\nTesting set label distribution:\")\n",
    "for label, count in test_label_counts.items():\n",
    "    print(f\"{label}: {count} ({count / total_test * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing Training Dataset:\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype = torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype = torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "    \n",
    "# Encoding string labels to integers:\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "val_labels_encoded = label_encoder.transform(val_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Print each label and its equivalent encoded label:\n",
    "for label, encoded_label in zip(label_encoder.classes_, range(len(label_encoder.classes_))):\n",
    "    print(f'Label: {label}, Encoded: {encoded_label}')\n",
    "    \n",
    "train_dataset = EEGDataset(train_features, train_labels_encoded)\n",
    "val_dataset = EEGDataset(val_features, val_labels_encoded)\n",
    "test_dataset = EEGDataset(test_features, test_labels_encoded)\n",
    "\n",
    "# Defining DataLoader:\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Transformer Model:\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, feature_dim, num_labels, model_dim = 256, num_heads = 8, encoder_layers = 16, ff_dim = 512, dropout_prob = 0.1, noise_level = 0.01):\n",
    "        \n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.noise_level = noise_level # Initialise noise level for input data augmentation.\n",
    "        self.input_projection = nn.Linear(feature_dim, model_dim) # Linear layer to project input features to model dimension.\n",
    "        self.input_dropout = nn.Dropout(dropout_prob) # Dropout for input projection layer.\n",
    "        \n",
    "        # Define a single transformer encoder layer with pre-LayerNorm (Dimensionality of the model, Number of attention heads, Dimension of the feedforward network, Dropout probability, Activation function, pre-layer normalisation):\n",
    "        encoder_layer = TransformerEncoderLayer(d_model = model_dim, nhead = num_heads, dim_feedforward = ff_dim, dropout = dropout_prob, activation = 'gelu', norm_first = True)\n",
    "\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers = encoder_layers) # Stack multiple transformer encoder layers.\n",
    "        self.batch_norm = nn.BatchNorm1d(model_dim) # Batch normalisation layer for transformer output.\n",
    "        self.output_projection = nn.Linear(model_dim, num_labels) # Linear layer to project transformer output to the number of classes.\n",
    "        self.output_dropout = nn.Dropout(dropout_prob) # Dropout for output projection layer.\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # Apply noise to inputs during training for regularisation:\n",
    "        if self.training and self.noise_level > 0.0:\n",
    "            noise = torch.randn_like(inputs) * self.noise_level\n",
    "            inputs = inputs + noise\n",
    "\n",
    "        inputs = self.input_projection(inputs) # Project inputs to the model dimension.\n",
    "        inputs = self.input_dropout(inputs) # Apply dropout to the projected inputs.\n",
    "        inputs = self.transformer_encoder(inputs) # Project inputs to the model dimension.\n",
    "        inputs = self.batch_norm(inputs) # Apply batch normalisation to the transformer outputs.\n",
    "        inputs = self.output_dropout(inputs) # Apply dropout to the transformer outputs.\n",
    "        inputs = self.output_projection(inputs) # Project the normalised outputs to the number of classes.\n",
    "\n",
    "        return F.log_softmax(inputs, dim = 1) # Return the log-softmax of the output projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Architecture:\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TransformerModel(feature_dim = train_features.shape[1], num_labels = len(np.unique(train_labels_encoded))).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with No Early Stopping and No Loss over Epoch:\n",
    "\n",
    "# Hyperparameters for Training:\n",
    "learning_rate = 1e-5 # Learning rate for the optimiser.\n",
    "epochs = 600 # Number of epochs to train the model.\n",
    "l1_lambda = 0.0001 # Lambda for L1 regularisation.\n",
    "train_accuracies = [] # List to store training accuracies for each epoch.\n",
    "val_accuracies = [] # List to store validation accuracies for each epoch.\n",
    "\n",
    "# Loss Function and Optimiser:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 1e-8)\n",
    "\n",
    "# Training Loop:\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Initialisation:\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train = 0\n",
    "    all_train_labels = [] \n",
    "    all_train_preds = [] \n",
    "\n",
    "    # Iterate over the training data loader:\n",
    "    for features, labels in train_loader:\n",
    "\n",
    "        features, labels = features.to(device), labels.to(device) \n",
    "        optimizer.zero_grad()\n",
    "        output = model(features)\n",
    "        loss = criterion(output, labels)\n",
    "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "        loss += l1_lambda * l1_norm  # L1 regularization\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        predictions = torch.max(output, 1)[1]\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy()) #Added this\n",
    "        all_train_preds.extend(predictions.cpu().numpy()) #Added this\n",
    "\n",
    "    train_accuracy = train_correct / total_train\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Validation:\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    total_val = 0\n",
    "    all_val_labels = [] \n",
    "    all_val_preds = [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            output = model(features)\n",
    "            loss = criterion(output, labels)\n",
    "            val_loss += loss.item()\n",
    "            predictions = torch.max(output, 1)[1]\n",
    "            val_correct += (predictions == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "            all_val_labels.extend(labels.cpu().numpy()) #Added this\n",
    "            all_val_preds.extend(predictions.cpu().numpy()) #Added this\n",
    "\n",
    "    val_accuracy = val_correct / total_val\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Print the training and validation metrics for the current epoch:\n",
    "    print(f'Epoch {epoch+1}, Loss: {train_loss / total_train}, Training Accuracy: {train_accuracy}, '\n",
    "          f'Validation Loss: {val_loss / total_val}, Validation Accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with No Early Stopping and with Accuracy and Loss over Epochs:\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparameters for Training:\n",
    "learning_rate = 1e-5 # Learning rate for the optimiser.\n",
    "epochs = 600 # Number of epochs to train the model.\n",
    "l1_lambda = 0.0001 # Lambda for L1 regularisation.\n",
    "train_accuracies = [] # List to store training accuracies for each epoch.\n",
    "val_accuracies = [] # List to store validation accuracies for each epoch.\n",
    "train_losses = [] # List to store training losses for each epoch.\n",
    "val_losses = [] # List to store validation losses for each epoch.\n",
    "\n",
    "# Loss Function and Optimiser:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 1e-8)\n",
    "\n",
    "# Training Loop:\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Initialisation:\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train = 0\n",
    "    all_train_labels = [] \n",
    "    all_train_preds = [] \n",
    "\n",
    "    # Iterate over the training data loader:\n",
    "    for features, labels in train_loader:\n",
    "\n",
    "        features, labels = features.to(device), labels.to(device) \n",
    "        optimizer.zero_grad()\n",
    "        output = model(features)\n",
    "        loss = criterion(output, labels)\n",
    "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "        loss += l1_lambda * l1_norm  # L1 regularization\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        predictions = torch.max(output, 1)[1]\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy()) #Added this\n",
    "        all_train_preds.extend(predictions.cpu().numpy()) #Added this\n",
    "\n",
    "    train_accuracy = train_correct / total_train\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_losses.append(train_loss / total_train) # Add train loss\n",
    "\n",
    "    # Validation:\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    total_val = 0\n",
    "    all_val_labels = [] \n",
    "    all_val_preds = [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            output = model(features)\n",
    "            loss = criterion(output, labels)\n",
    "            val_loss += loss.item()\n",
    "            predictions = torch.max(output, 1)[1]\n",
    "            val_correct += (predictions == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "            all_val_labels.extend(labels.cpu().numpy()) #Added this\n",
    "            all_val_preds.extend(predictions.cpu().numpy()) #Added this\n",
    "\n",
    "    val_accuracy = val_correct / total_val\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_losses.append(val_loss / total_val) # Add validation loss\n",
    "\n",
    "    # Print the training and validation metrics for the current epoch:\n",
    "    print(f'Epoch {epoch+1}, Loss: {train_loss / total_train}, Training Accuracy: {train_accuracy}, '\n",
    "          f'Validation Loss: {val_loss / total_val}, Validation Accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with Early Stopping and with Accuracy and Loss over Epochs:\n",
    "\n",
    "# Hyperparameters for Training:\n",
    "learning_rate = 1e-5 # Learning rate for the optimiser.\n",
    "epochs = 600 # Number of epochs to train the model.\n",
    "l1_lambda = 0.0001 # Lambda for L1 regularisation.\n",
    "train_accuracies = [] # List to store training accuracies for each epoch.\n",
    "val_accuracies = [] # List to store validation accuracies for each epoch.\n",
    "train_losses = [] # List to store training losses for each epoch.\n",
    "val_losses = [] # List to store validation losses for each epoch.\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 10\n",
    "best_val_loss = np.inf\n",
    "patience_counter = 0\n",
    "\n",
    "# Loss Function and Optimiser:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 1e-8)\n",
    "\n",
    "# Training Loop:\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Initialisation:\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train = 0\n",
    "    all_train_labels = [] \n",
    "    all_train_preds = [] \n",
    "\n",
    "    # Iterate over the training data loader:\n",
    "    for features, labels in train_loader:\n",
    "\n",
    "        features, labels = features.to(device), labels.to(device) \n",
    "        optimizer.zero_grad()\n",
    "        output = model(features)\n",
    "        loss = criterion(output, labels)\n",
    "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "        loss += l1_lambda * l1_norm  # L1 regularization\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        predictions = torch.max(output, 1)[1]\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy()) #Added this\n",
    "        all_train_preds.extend(predictions.cpu().numpy()) #Added this\n",
    "\n",
    "    train_accuracy = train_correct / total_train\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_losses.append(train_loss / total_train) # Add train loss\n",
    "\n",
    "    # Validation:\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    total_val = 0\n",
    "    all_val_labels = [] \n",
    "    all_val_preds = [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            output = model(features)\n",
    "            loss = criterion(output, labels)\n",
    "            val_loss += loss.item()\n",
    "            predictions = torch.max(output, 1)[1]\n",
    "            val_correct += (predictions == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "            all_val_labels.extend(labels.cpu().numpy()) #Added this\n",
    "            all_val_preds.extend(predictions.cpu().numpy()) #Added this\n",
    "\n",
    "    val_accuracy = val_correct / total_val\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_losses.append(val_loss / total_val) # Add validation loss\n",
    "\n",
    "    # Print the training and validation metrics for the current epoch:\n",
    "    print(f'Epoch {epoch+1}, Loss: {train_loss / total_train}, Training Accuracy: {train_accuracy}, '\n",
    "          f'Validation Loss: {val_loss / total_val}, Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "    # Early Stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), 'Phase_1/Final_Models/CNN_Model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Trained Model:\n",
    "\n",
    "model_path = 'Phase_1/Final_Models/Transformer_Model.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f'Model saved to {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Early Stopping: \n",
    "\n",
    "# Hyperparameters for Training:\n",
    "learning_rate = 1e-5  # Learning rate for the optimiser.\n",
    "epochs = 1000  # Number of epochs to train the model.\n",
    "l1_lambda = 0.0001  # Lambda for L1 regularisation.\n",
    "patience = 10  # Patience for early stopping.\n",
    "best_val_loss = float('inf')  # Best validation loss initialized to infinity.\n",
    "early_stop_counter = 0  # Counter for early stopping.\n",
    "\n",
    "train_accuracies = []  # List to store training accuracies for each epoch.\n",
    "val_accuracies = []  # List to store validation accuracies for each epoch.\n",
    "\n",
    "# Loss Function and Optimiser:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\n",
    "\n",
    "# Training Loop:\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Initialisation:\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train = 0\n",
    "    all_train_labels = []\n",
    "    all_train_preds = []\n",
    "\n",
    "    # Iterate over the training data loader:\n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(features)\n",
    "        loss = criterion(output, labels)\n",
    "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "        loss += l1_lambda * l1_norm  # L1 regularization\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        predictions = torch.max(output, 1)[1]\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "    train_accuracy = train_correct / total_train\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Validation:\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    total_val = 0\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            output = model(features)\n",
    "            loss = criterion(output, labels)\n",
    "            val_loss += loss.item()\n",
    "            predictions = torch.max(output, 1)[1]\n",
    "            val_correct += (predictions == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "    val_accuracy = val_correct / total_val\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Print the training and validation metrics for the current epoch:\n",
    "    print(f'Epoch {epoch+1}, Loss: {train_loss / total_train}, Training Accuracy: {train_accuracy}, '\n",
    "          f'Validation Loss: {val_loss / total_val}, Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "    # Early stopping:\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "        # Save the model if the validation loss decreases\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            model.load_state_dict(torch.load('best_model.pt'))  # Load the best model\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Loss:\n",
    "\n",
    "epochs_range = range(1, epochs + 1)\n",
    "\n",
    "plt.figure(figsize = (8, 6))\n",
    "plt.plot(epochs_range, train_losses, label = 'Train Loss', color = 'blue')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (8, 6))\n",
    "plt.plot(epochs_range, val_losses, label = 'Validation Loss', color = 'orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotting Validation Accuracy:\n",
    "plt.figure(figsize = (8, 6))\n",
    "plt.plot(epochs_range, val_accuracies, label = 'Validation Accuracy', color = 'green')\n",
    "plt.xlabel('Epochs') \n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function:\n",
    "\n",
    "def calculate_metrics(labels, preds, dataset_name):\n",
    "\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average = 'weighted')\n",
    "    recall = recall_score(labels, preds, average = 'weighted')\n",
    "    f1 = f1_score(labels, preds, average = 'weighted')\n",
    "    class_report = classification_report(labels, preds)\n",
    "    conf_matrix = confusion_matrix(labels, preds)\n",
    "    std_dev = np.std(preds)\n",
    "    kappa = cohen_kappa_score(labels, preds)\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "\n",
    "    # Binarize the labels for ROC curve calculation\n",
    "    n_classes = 10\n",
    "    labels_binarized = label_binarize(labels, classes = range(n_classes))\n",
    "    preds_binarized = label_binarize(preds, classes = range(n_classes))\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class:\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(labels_binarized[:, i], preds_binarized[:, i])\n",
    "        roc_auc[i] = roc_auc_score(labels_binarized[:, i], preds_binarized[:, i])\n",
    "\n",
    "     # Compute Precision-Recall curve and PR area for each class:\n",
    "    precision_curve = dict()\n",
    "    recall_curve = dict()\n",
    "    average_precision = dict()\n",
    "    for i in range(n_classes):\n",
    "        precision_curve[i], recall_curve[i], _ = precision_recall_curve(labels_binarized[:, i], preds_binarized[:, i])\n",
    "        average_precision[i] = average_precision_score(labels_binarized[:, i], preds_binarized[:, i])\n",
    "\n",
    "    print(f'---------- {dataset_name} Evaluation Metrics: ----------\\n')\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1-score: {f1:.4f}')\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(f'Cohen\\'s Kappa: {kappa:.4f}')\n",
    "    print(f'Matthews Correlation Coefficient: {mcc:.4f}')\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print('Classification Report:')\n",
    "    print(class_report)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print('Confusion Matrix:')\n",
    "    print(\"\\n\")\n",
    "    plt.figure(figsize = (10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap = 'Blues', xticklabels = words, yticklabels = words)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title(f'{dataset_name} Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    print(f'Standard Deviation: {std_dev:.4f}\\n')\n",
    "\n",
    "    print(\"ROC Curve and AUC Scores: \")\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize = (10, 7))\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color = color, lw = 2,\n",
    "                 label = f'ROC curve of class {words[i]} (area = {roc_auc[i]:0.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw = 2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{dataset_name} ROC Curve')\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Precision-Recall Curve: \")\n",
    "    # Plot Precision-Recall curve\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(recall_curve[i], precision_curve[i], color = color, lw = 2,\n",
    "                 label=f'PR curve of class {words[i]} (area = {average_precision[i]:0.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [1, 0], 'k--', lw = 2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'{dataset_name} Precision-Recall Curve')\n",
    "    plt.legend(loc = \"lower left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for the Training and Validation Sets:\n",
    "\n",
    "calculate_metrics(all_train_labels, all_train_preds, dataset_name = f'Training')\n",
    "calculate_metrics(all_val_labels, all_val_preds, dataset_name = f'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for the Testing Set:\n",
    "\n",
    "model.eval()\n",
    "all_test_labels = []\n",
    "all_test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        output = model(features)\n",
    "        predictions = torch.max(output, 1)[1]\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Calculate and display metrics for the test set\n",
    "calculate_metrics(all_test_labels, all_test_preds, dataset_name = 'Test Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time Predictions:\n",
    "\n",
    "def predict(model, input_data, device):\n",
    "    model.eval()\n",
    "    input_data = torch.tensor(input_data, dtype = torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "    return predicted.cpu().numpy()\n",
    "\n",
    "# Load the trained model weights\n",
    "model.load_state_dict(torch.load('Phase_1/Final_Models/Transformer_Model.pth'))\n",
    "\n",
    "# Example usage\n",
    "sample_inputs = test_features[:10]  # Take five samples from the test set\n",
    "actual_labels = test_labels[:10]\n",
    "\n",
    "predicted_labels = predict(model, sample_inputs, device)\n",
    "\n",
    "# Print actual vs predicted labels\n",
    "for actual, predicted in zip(actual_labels, predicted_labels):\n",
    "    print(f'Actual: {label_encoder.inverse_transform([actual])[0]}, Predicted: {label_encoder.inverse_transform([predicted])[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
